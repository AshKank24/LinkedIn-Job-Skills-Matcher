{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to check the similarity between a Candidate and a Job Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input \n",
    "\n",
    "### LinkedIn Username\n",
    "### LinkedIn Password\n",
    "### Candidate Profile Link\n",
    "### Job Description Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"Username\" #Your Username\n",
    "\n",
    "password = \"Password\" #Your Password\n",
    "\n",
    "candidate_link = \"Username\" #Candidate Link on LinkedIn\n",
    "\n",
    "job_link = \"Job_Link\" #Job Link on LinkedIn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "### Similarity Score of these can be used to compare various candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Download Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import csv\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tag import pos_tag\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB 7.9 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 17.2 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 17.5 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.9/12.8 MB 15.5 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 2.8/12.8 MB 14.0 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.0/12.8 MB 12.7 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 11.2 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.1/12.8 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.1/12.8 MB 11.8 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.6/12.8 MB 10.8 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.8/12.8 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.8/12.8 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.9/12.8 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.9/12.8 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.9/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.7/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.1/12.8 MB 10.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.5/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.8/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 10.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 10.0 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 10.0/12.8 MB 10.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.6/12.8 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 8.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (58.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\kanka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kanka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the selenium driver\n",
    "\n",
    "### Might need to update the chrome version in accordance to the selenium driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(service=Service(r\"chromedriver.exe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Login to LinkedIn of the given User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(r\"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get(\"https://www.linkedin.com/login\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "username_field = driver.find_element(By.ID, \"username\")\n",
    "username_field.send_keys(username)\n",
    "password_field = driver.find_element(By.ID, \"password\")\n",
    "password_field.send_keys(password)\n",
    "\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(job_link)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Job Description from the Job Profile\n",
    "\n",
    "### Need to change the \"jobs-description-content__text\" here according to the class name of the job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About the job\n",
      "About Ascendion\n",
      "Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.\n",
      "\n",
      "Ascendion | Engineering to elevate life | www.ascendion.com\n",
      "\n",
      "We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:\n",
      "Build the coolest tech for the world’s leading brands\n",
      "Solve complex problems - and learn new skills\n",
      "Experience the power of transforming digital engineering for Fortune 500 clients\n",
      "Master your craft with leading training programs and hands-on experience\n",
      "\n",
      "Experience a community of change-makers!\n",
      "Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\n",
      "\n",
      "About the Role:\n",
      "\n",
      "Location: Pune, MH, and Chennai, TN (hybrid work)\n",
      "\n",
      "Description:\n",
      "Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone, Milvus, Neo4j)\n",
      "Hands-on experience using Open AI APIs, and Open Source LLMs (Llama2, Mistral, Mixtral, etc.)\n",
      "Solid understanding of frameworks like Langchain, and Haystack, and ability to use Agentic Workflows using those frameworks\n",
      "Experience with Speech-to-Text using Whisper/Google TTS etc.\n",
      "Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET, Ada models\n",
      "Ability to use advanced techniques like HyDE, MMR, and LLM reranking for effective semantic search\n",
      "Experience with Chat, IVR, and Banking will be a plus\n",
      "\n",
      "Want to change the world? Let us know.\n",
      "Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!\n"
     ]
    }
   ],
   "source": [
    "job_details_element = driver.find_element(By.CLASS_NAME, \"jobs-description-content__text\")\n",
    "\n",
    "job_details_text = job_details_element.text\n",
    "\n",
    "print(job_details_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Skills: ['Ability to use advanced techniques like HyDE', 'Good understanding and experience using Transformer/Neural Network model\\nHands-on experience in creating Embedding using MPNET', 'Solid understanding of frameworks like Langchain', 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\\nHands-on experience with Vector Database & Graph DB (Pinecone', 'Experience with Speech-to-Text using Whisper/Google TTS etc', 'Experience with Chat']\n"
     ]
    }
   ],
   "source": [
    "def extract_skills(job_description):\n",
    "    skills = []\n",
    "    \n",
    "    description_index = job_description.find(\"Description:\")\n",
    "    skills_index = job_description.find(\"Required Skills\")\n",
    "    \n",
    "    if description_index != -1:\n",
    "        skills_section = job_description[description_index:]\n",
    "        if skills_index != -1:\n",
    "            skills_section = skills_section[:skills_index]\n",
    "        \n",
    "        skills.extend(re.findall(r'(?:Hands-on with|Experience with|Good understanding and experience using|Ability to use|Solid understanding of|Hands-on experience in|Familiarity with)[\\sA-Za-z&/\\-()]+', skills_section))\n",
    "    \n",
    "    skills = list(set(filter(None, skills)))\n",
    "    \n",
    "    return skills\n",
    "\n",
    "job_skills = extract_skills(job_details_text)\n",
    "\n",
    "print(\"Extracted Skills:\", job_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically browses the Candidate Link and extract unique skills of the candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_link = candidate_link + \"/details/skills/\"\n",
    "driver.get(cand_link)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Skills: ['Data Modeling', 'React.js', 'C++', 'HTML', 'Deep Learning', 'Problem Solving', 'Machine Learning', 'Python (Programming Language)', 'Artificial Intelligence (AI)', 'MySQL', 'ChatGPT', 'Cascading Style Sheets (CSS)', 'Research Skills', 'Teamwork', 'Generative AI', 'Android Development', 'Team Leadership', 'Java']\n"
     ]
    }
   ],
   "source": [
    "html_content = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "section = soup.find(\"section\", class_=\"artdeco-card pb3\")\n",
    "\n",
    "if section:\n",
    "    skill_containers = section.find_all(\"div\", class_=\"display-flex align-items-center mr1 hoverable-link-text t-bold\")\n",
    "\n",
    "    skills = [container.text.strip() for container in skill_containers]\n",
    "\n",
    "else:\n",
    "    print(\"Section not found\")\n",
    "\n",
    "unique_skills = list(set(skill[:len(skill)//2 + len(skill)%2] for skill in skills))\n",
    "\n",
    "print(\"Unique Skills:\", unique_skills)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Preprocessing of the data and computation of cosine similarities between job and candidate skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kanka\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Data Modeling': 0.07\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'React.js': -0.02\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'C++': 0.06\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'HTML': 0.06\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Deep Learning': 0.26\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Problem Solving': 0.10\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Machine Learning': 0.24\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Python (Programming Language)': 0.05\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Artificial Intelligence (AI)': 0.36\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'MySQL': 0.05\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'ChatGPT': 0.12\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Cascading Style Sheets (CSS)': 0.05\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Research Skills': 0.27\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Teamwork': 0.20\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Generative AI': 0.33\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Android Development': 0.05\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Team Leadership': 0.22\n",
      "Similarity between 'Ability to use advanced techniques like HyDE' and 'Java': 0.20\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Data Modeling': 0.19\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'React.js': -0.06\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'C++': 0.06\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'HTML': 0.09\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Deep Learning': 0.21\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Problem Solving': 0.08\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Machine Learning': 0.12\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Python (Programming Language)': 0.11\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Artificial Intelligence (AI)': 0.14\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'MySQL': 0.01\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'ChatGPT': 0.12\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Cascading Style Sheets (CSS)': 0.00\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Research Skills': 0.15\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Teamwork': 0.10\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Generative AI': 0.18\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Android Development': 0.10\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Team Leadership': 0.10\n",
      "Similarity between 'Good understanding and experience using Transformer/Neural Network model\n",
      "Hands-on experience in creating Embedding using MPNET' and 'Java': 0.06\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Data Modeling': 0.11\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'React.js': 0.12\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'C++': 0.13\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'HTML': 0.15\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Deep Learning': 0.17\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Problem Solving': 0.04\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Machine Learning': 0.09\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Python (Programming Language)': 0.27\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Artificial Intelligence (AI)': 0.03\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'MySQL': -0.02\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'ChatGPT': 0.17\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Cascading Style Sheets (CSS)': 0.01\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Research Skills': 0.08\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Teamwork': 0.12\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Generative AI': 0.06\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Android Development': 0.21\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Team Leadership': 0.03\n",
      "Similarity between 'Solid understanding of frameworks like Langchain' and 'Java': 0.22\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Data Modeling': 0.30\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'React.js': 0.03\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'C++': 0.18\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'HTML': 0.06\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Deep Learning': 0.13\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Problem Solving': 0.10\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Machine Learning': 0.23\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Python (Programming Language)': 0.05\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Artificial Intelligence (AI)': 0.03\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'MySQL': 0.20\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'ChatGPT': 0.19\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Cascading Style Sheets (CSS)': 0.05\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Research Skills': 0.10\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Teamwork': 0.09\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Generative AI': 0.09\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Android Development': 0.16\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Team Leadership': 0.02\n",
      "Similarity between 'Hands-on with LLMs (In previous projects) and worked on product development using LLMs\n",
      "Hands-on experience with Vector Database & Graph DB (Pinecone' and 'Java': 0.16\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Data Modeling': 0.11\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'React.js': 0.09\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'C++': 0.11\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'HTML': 0.16\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Deep Learning': 0.23\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Problem Solving': 0.13\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Machine Learning': 0.18\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Python (Programming Language)': 0.11\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Artificial Intelligence (AI)': 0.08\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'MySQL': 0.14\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'ChatGPT': 0.26\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Cascading Style Sheets (CSS)': 0.08\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Research Skills': 0.23\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Teamwork': 0.19\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Generative AI': 0.18\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Android Development': 0.17\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Team Leadership': 0.14\n",
      "Similarity between 'Experience with Speech-to-Text using Whisper/Google TTS etc' and 'Java': 0.13\n",
      "Similarity between 'Experience with Chat' and 'Data Modeling': 0.12\n",
      "Similarity between 'Experience with Chat' and 'React.js': 0.04\n",
      "Similarity between 'Experience with Chat' and 'C++': 0.16\n",
      "Similarity between 'Experience with Chat' and 'HTML': 0.17\n",
      "Similarity between 'Experience with Chat' and 'Deep Learning': 0.21\n",
      "Similarity between 'Experience with Chat' and 'Problem Solving': 0.17\n",
      "Similarity between 'Experience with Chat' and 'Machine Learning': 0.18\n",
      "Similarity between 'Experience with Chat' and 'Python (Programming Language)': 0.15\n",
      "Similarity between 'Experience with Chat' and 'Artificial Intelligence (AI)': 0.18\n",
      "Similarity between 'Experience with Chat' and 'MySQL': 0.22\n",
      "Similarity between 'Experience with Chat' and 'ChatGPT': 0.51\n",
      "Similarity between 'Experience with Chat' and 'Cascading Style Sheets (CSS)': 0.06\n",
      "Similarity between 'Experience with Chat' and 'Research Skills': 0.16\n",
      "Similarity between 'Experience with Chat' and 'Teamwork': 0.20\n",
      "Similarity between 'Experience with Chat' and 'Generative AI': 0.24\n",
      "Similarity between 'Experience with Chat' and 'Android Development': 0.17\n",
      "Similarity between 'Experience with Chat' and 'Team Leadership': 0.12\n",
      "Similarity between 'Experience with Chat' and 'Java': 0.24\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading BERT model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    keywords = [word for word, tag in pos_tags if tag.startswith('N')]\n",
    "    return ' '.join(keywords)\n",
    "\n",
    "candidate_skills_processed = [extract_keywords(skill) for skill in unique_skills]\n",
    "job_skills_processed = [extract_keywords(skill) for skill in job_skills]\n",
    "\n",
    "candidate_embeddings = model.encode(candidate_skills_processed, convert_to_tensor=True)\n",
    "job_embeddings = model.encode(job_skills_processed, convert_to_tensor=True)\n",
    "\n",
    "cosine_similarities = util.pytorch_cos_sim(job_embeddings, candidate_embeddings)\n",
    "\n",
    "for i, job_skill in enumerate(job_skills):\n",
    "    for j, candidate_skill in enumerate(unique_skills):\n",
    "        similarity_score = cosine_similarities[i][j].item()\n",
    "        print(f\"Similarity between '{job_skill}' and '{candidate_skill}': {similarity_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate a similarity score between the candidate skills and the skills required by the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall similarity score for the candidate: 0.24\n"
     ]
    }
   ],
   "source": [
    "max_scores = []\n",
    "\n",
    "for j, candidate_skill in enumerate(unique_skills):\n",
    "    max_score = 0\n",
    "    for i, job_skill in enumerate(job_skills):\n",
    "        similarity_score = cosine_similarities[i][j].item()\n",
    "        if similarity_score > max_score:\n",
    "            max_score = similarity_score\n",
    "    max_scores.append(max_score)\n",
    "\n",
    "overall_score = np.mean(max_scores)\n",
    "\n",
    "print(f\"Overall similarity score for the candidate: {overall_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This score can be used to compare and rank various candidates for the job profile."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
